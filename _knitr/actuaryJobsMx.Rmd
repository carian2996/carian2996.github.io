---
title: "El Trabajo del Actuario en México"
author: "Ian Castillo"
date: "24 de enero de 2017"
output: html_document
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r libraries, message=FALSE, warning=FALSE, include=FALSE, cache=TRUE}
packages <- c("ggplot2", "dplyr", "stringr", "wordcloud", "RColorBrewer", "devtools",
              "tm", "SnowballC", "devtools", "Hmisc", "cluster", "fpc", "knitr")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
    install.packages(setdiff(packages, rownames(installed.packages())))  
} else print("Todos los paquetes instalados")

devtools::install_github("dashee87/jobbR")
devtools::install_github('diegovalle/mxmaps')

lapply(packages, require, character.only = TRUE)
require(jobbR)
```

```{r data, message=FALSE, warning=FALSE, include=FALSE, cache=FALSE}
load('~/Documents/RCode/actuaryJobsMx/dataset.RData')
```



El presente escrito está basado en el trabajo de David Sheehan publicado [aquí](http://dashee87.github.io/data%20science/data-scientists-vs-data-analysts-part-1/).

De igual manera, se agradece la ayuda de los siguientes recursos:

* [**Basic Text Mining in R**](https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html) de *RStudio*
* [**jobbR**](https://github.com/dashee87/jobbR) de *David Sheehan*
* [**mxmaps**](https://github.com/diegovalle/mxmaps) de *Diego Valle*
* [**outlierKD**](https://datascienceplus.com/rscript/outlier.R) de *Klodian Dhana*

## Objetivo
Este pequeño análisis presenta la situación actual respecto a los trabajos ofrecidos en México para las personas egresadas de la carrera de Actuaría.

De acuerdo con el artículo publicado por El Universal (2015) en su nota [Matemáticas vs desempleo](http://www.eluniversal.com.mx/articulo/periodismo-de-datos/2015/08/3/matematicas-vs-desempleo), una de las carreras profesionales mejor pagas es la del actuario, con un **sueldo promedio de 21 mil pesos al mes** y con una **tasa de desempleo del 0%**. Su análisis está basado en la [Encuesta Nacional de Ocupación y Empleo](http://www.beta.inegi.org.mx/proyectos/enchogares/regulares/enoe/) y las cifras corresponden al primer trimestre del 2015.

En esta breve publicación analizaremos las solicitudes de trabajo enfocadas a las personas egresadas de la licenciatura en Actuaría<sup>*</sup>.

Los datos, código fuente y reporte se pueden encontrar directamente [aquí](https://github.com/carian2996/RCode/tree/master/actuaryJobsMx).

\* *Nos basaremos en el supuesto de que al hacer una consulta en el portal de empleos Indeed con la consulta 'actuaria', los datos arrojados están relacionados con la oferta laboral para los actuarios. La consulta se realiza por orden de 'Relevancia'.*

## Los Datos
Los datos se obtuvieron de [Indeed](https://www.indeed.com.mx/about), un sitio web de busqueda de empleo cuya [API](https://www.indeed.com.mx/publisher) nos permite descargar la información relacionada con la publicación de una oferta de trabajo.

Con la ayuda del paquete desarrollado por **David Sheehan**, podemos acceder fácilmente a los datos requeridos. Una simple consulta con el siguiente código basta para obtener los datos de las solicitudes y sus respectivos sueldos:

```
# Obtenemos la información proporcionada por la empresa reclutadora
actuarios <- jobSearch(publisher = API Key,         # Contraseña obtenida para la API
                      query = "actuaria",           # Busqueda
                      country = 'mx',               # País
                      all = TRUE)                   # Regresa todos las solicitudes
                      
# Basados en la URL del puesto, registramos el salario ofrecido
salarios <- lapply(actuarios$results.url,               # URL de la solicitud
                   function(x) getSalary(x, "USD"))     # Extraemos el salario ofrecido
                   
# Cada salario obtenido lo guardamos en un data.frame
salarios <- do.call(rbind, salarios)

# Anexamos ambos conjunto de datos
actuarios <- cbind(actuarios, salarios)
```

Para este análisis se utlizaron `r nrow(actuarios)` solicitudes de trabajo, desde el `r substr(max(actuarios$results.date), 6, 16)` hasta el `r substr(min(actuarios$results.date), 6, 16)` con las características de la consulta previa. El data set utilizado aquí puede ser descargado desde [aquí](https://raw.githubusercontent.com/carian2996/RCode/master/actuaryJobsMx/data.csv).

## Limpieza de los datos
Lo primero que haremos será una rápida limpieza de nuestros datos. Los datos en crudo contienen la siguiente información:

```{r colnames_prev, echo=FALSE, message=FALSE, warning=FALSE}
colnames(actuarios)
```

De las variables anteriores podemos notar que las primeras 10 columnas no tienen mayor relevancia, pues solo representan meta datos de nuestra consulta.

```{r head, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(head(actuarios[, 1:10], 5))
```

```{r delete-cols, message=FALSE, warning=FALSE, include=FALSE}
actuarios <- actuarios[, -(1:10)]
colnames(actuarios) <- gsub('results.', '', colnames(actuarios))
```

Eliminamos las columnas innecesarias y además, renombramos las columnas eliminando el prefijo 'results' para una compresión más sencilla y manejo más efectivo de las columnas. Las variables que tenemos para trabajar entonces son las siguientes:

```{r colnames, echo=FALSE, message=FALSE, warning=FALSE}
colnames(actuarios)
```

Examinemos más a detalle que variables tenemos para trabajar. No incluimos 'snippet' porque es la variable que posee el texto original de las solicitudes, de igual manera 'url' pues solo contiene la dirección de la vacante.

```{r structure, echo=FALSE, warning=FALSE}
str(actuarios[, -(9:10)])
```

Así se ve nuestros datos por el momento (sin la descripción del puesto ni url, pues son muy largas para mostrarse en una tabla):

```{r , results='asis', echo=FALSE, message=FALSE, warning=FALSE}
pander::pander(head(actuarios[, -(9:10)], 3))
```

## Compañías que más contratan actuarios
Una vez listos nuestros datos, podemos empezar a analizar y descubrir que hechos interesantes podemos obtener. Utilizando la información sobre la compañía que emite la vacante, veamos quienes son las empresas que más solicitan puestos para egresados de actuarios

```{r companies, echo=TRUE, message=FALSE, warning=FALSE}
require(dplyr)

actuarios <- actuarios %>%
    mutate(company = tolower(company)) %>%
    mutate(company = gsub('[[:punct:]]+', ' ', company)) %>%
    mutate(company = gsub('[[:digit:]]+', ' ', company)) %>%
    mutate(company = iconv(company, to='ASCII//TRANSLIT')) %>%
    mutate(company = gsub('[[:punct:]]+', '', company))

# Generamos una tabla de frecuencias con las compañías que ofrecen los empleos
compañias <- sort(table(actuarios$company), decreasing = T)

# Removemos compañias con pocos puestos
dfCompañias <- data.frame(compañias[compañias / sum(compañias) > 0.009])   

# Cambiamos el nombre de nuestra columnas
colnames(dfCompañias) <- c('compañia', 'puestos')

# Recortamos el nombre de la compañia (para efectos de visualización)
dfCompañias$compañia <- substr(dfCompañias$compañia, 1, 15)                 

# Removemos compañias sin nombre
dfCompañias <- dfCompañias[dfCompañias$compañia != '', ]

dfCompañias$compañia <- factor(dfCompañias$compañia, 
                               levels=dfCompañias$compañia)
```


```{r plot1, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
require(ggplot2)

ggplot2::ggplot(dfCompañias, aes(x = compañia, y = puestos)) + 
    geom_bar(stat = "identity", fill="#1756A9") + 
    theme(plot.subtitle = element_text(vjust = 1), 
          plot.caption = element_text(vjust = 1), 
          axis.text.x = element_text(angle = 40, hjust = 1), 
          plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
    labs(title = "Empresas con Mayor Demanda de Actuarios", 
         x = NULL, y = "Total de Solicitudes")
```

Podemos observar que entre las compañías con más puestos ofrecidos, se encuentras reclutadoras o compañías de 'head hunting', lo cual no deja entrevisto la verdadera empresa que solicita el puesto. Aunque por mucho, notamos que **Banamex** -ahora conocido como Citibanamex- es la institución con más vacantes relacionadas con la consulta 'actuaria'. 

Recordemos que cualquier análasis no debe ser tomado como verdad absoluta, por lo que podríamos hacer pensar que esto no necesariamente nos dice que Banamex ofrece más empleo para los actuarios, podemos considerar que esta institución financiera es muy grande comparada con muchas otras o incluso puede tener un convenio con Indeed para colocar más vacantes que otras empresas.

# El trabajo de actuario en alrededor del país
Desde que se ofreció por primera vez la licenciatura en Actuaría en la Ciudad de México (1947), dicha carrera profesional ha sido testigo de una divulgación alrededor del país; teniendo en cuenta que ahora se puede estudiar la carrera hasta en 10 ciudades de la república, podríamos esperar que el trabajo del actuario se ejerza en todo el país.

A continuación, analizaremos como se encuentran distribuidos los trabajos en la república Mexicana. El siguiente código preparará los datos de tal manera que con la ayuda del paquete de **Diego Valle** podremos graficar nuestros datos con un mapa de México utlizando dos lineas de código. 

```{r mapa, echo=TRUE, message=FALSE, warning=FALSE}
# Llamamos al paquete mxmaps para preparar la plantilla a utilizar
require(mxmaps)
data("df_mxstate")

# Creamos nuestra tabla de frecuencias por estado
mapa <- data.frame(table(actuarios$state))

# Adecuamos las abreviaturas de los estados y la unimos con la plantilla 
# necesaria para utlizar el paquete mxmaps
colnames(mapa) <- c('estado', 'puestos')
mapa <- mapa[mapa$estado != '', ]
mapa$estado <- c('BC', 'CHIH',  'CDMX', 'DGO', 'GTO', 'JAL', 'MEX', 'MICH', 'NL', 
                 'PUE', 'QRO', 'QROO', 'SIN', 'SON', 'TAB', 'TAM', 'YUC')

mapa <- merge(x=df_mxstate,y=mapa, by.x="state_abbr", by.y="estado", all.x = TRUE)
mapa$value <- mapa$puestos

# Reemplazamos los valores nulos por el valor 0
mapa$value[is.na(mapa$value)] <- 0
```

El siguiente mapa muestra la relación que existe entre los estados que poseen alguna universidad (pública o privada) y el número de empleos que se ofrece en dicha entidad o sus alrededores. 

```{r mapa2, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
mxstate_choropleth(mapa, title = "Trabajos ofrecidos en México") 
```

Por supuesto, la Ciudad de México, el Estado de México y Nuevo León encabezan la lista de estados de la republica dónde un actuario puede ejercer su labor. Aunque cabe resaltar los estados de Jalisco, Yucatán, y Puebla que apesar de tener menor tiempo con alguna universidad instaurando la carrera de Actuaría, ya comienzan a destacar entre las entidades que requieren este tipo de profesionista.

Quisiera destacar el dato del estado de Coahuila. En mi experiencia personal, nunca he conocido empresas que requieran actuarios en aquella entidad, ni de conocidos que hayan recibido ofertas en esa parte del país. Si ustedes tienen alguna explicación sobre este dato atípico (atípico a mi juicio) que nos pueda aclarar más la situación no estaría de más comenarlo.

# Algo de Minería de Texto
Me gustaría analizar las descripciones de las vacantes ofrecidas y poder vislumbrar un poco cuáles son los requisitos que más se le pide a una persona que quiera trabajar como actuario. Qué palabras son las más comunes a la hora de solicitar una actuaria o que habilidades están relacionadas con puestos actuariales de nivel dirección o gerencial.

Primero que nada, debemos preparar nuestros textos, juntarlos y realizar un procesamientos para poder anaizarlos. Con el siguiente código realizamos dicha tarea.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
require(tm)
# Cargamos y preparamos el corpus de datos

# Asociamos cada documentos con su id única de vacante
reader <- readTabular(mapping = list(id = "jobkey", content = "snippet"))

# Preparamos el corpus y definimos el lenguaje del texo
corpus <- Corpus(DataframeSource(actuarios), 
                 readerControl = list(reader = reader, language = 'es'))
```

Una vez creado el corpus con las siguientes características:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
corpus
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
inspect(corpus[1])
```

Realizamos la limpieza del texto:

```{r}
require(tm)

# ===== Procesamientos de los documentos =====
skipWords <- function(x) removeWords(x, stopwords("spanish"))
funcs <- list(content_transformer(tolower), 
              removePunctuation, 
              removeNumbers, 
              stripWhitespace, 
              skipWords)
c_corpus <- tm_map(corpus, FUN = tm_reduce, tmFuns = funcs)

# Cambiamos las palabras que se generan erroneamente
for (j in seq(c_corpus)) c_corpus[[j]] <- gsub("bactuaríab", "actuaría", c_corpus[[j]])
for (j in seq(c_corpus)) c_corpus[[j]] <- gsub("bactuariab", "actuaría", c_corpus[[j]])

# Utlizando el algoritmos de Porter cambiamos las palabras plurales a singulares
c_corpus <- tm_map(c_corpus, stemDocument, language = 'es')

# Convertimos nuestros documentos a texto plano para agregar meta datos
c_corpus <- tm_map(c_corpus, PlainTextDocument) 

for (i in 1:length(c_corpus)) meta(c_corpus[[i]], 'id') <- actuarios$jobkey[i]
for (i in 1:length(c_corpus)) meta(c_corpus[[i]], 'author') <- actuarios$company[i]
for (i in 1:length(c_corpus)) meta(c_corpus[[i]], 'datetimestamp') <- actuarios$date[i]
for (i in 1:length(c_corpus)) meta(c_corpus[[i]], 'heading') <- actuarios$jobtitle[i]
for (i in 1:length(c_corpus)) meta(c_corpus[[i]], 'language') <- 'spanish'
```

Una vez hecho el procesamiento y transformación sobre nuestros datos, el resultado final es els siguiente:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
c_corpus[[400]]['content']
```

# Palabras más frecuentas en la busqueda de un actuario
Para realizar todos nuestros análisis debemos de construir la llamada matriz de términos del documentos. Dicha matriz relaciona todas las palabras registradas en los textos y sus apariciones dentro del mismo. Con el siguiente código creamos dicha matriz.

```{r, message=FALSE, warning=FALSE}
require(tm)
(dtm <- DocumentTermMatrix(c_corpus))
```

Más adelantes, removeremos las palabras menos frecuentes utilizando la función 'removeSparseTerms'. Esta parte del análisis es de gran sensibilidad, pues al eliminar las palabras menos frecuentes podríamos estar sesgando el significado de éstas de acuerdo al contexto que incluye el documento.

Una gran explicación acerca de 'escasez' de palabras en la matriz de términos puede ser vista [aquí](http://stackoverflow.com/a/33830637).

Con el siguiente código podemos ver las palabras más frecuentes en nuestro corpus

```{r, echo=TRUE, message=FALSE, warning=FALSE}
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
head(freq)
```

Las cuales son palabras esperadas, obviamente, 'actuaria' es la palabra más común pues nuestra busqueda fue esa palabra precisamente.

Para comprender más acerca de la escasez en los documentos, analicemos que tan seguido se repiten las frecuencias de los términos en nuestra matriz.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
table(freq)
```
Lo anterior quiere decir que existen `r max(table(freq))` términos que se encuentran solo en un texto de una vacante; `r table(freq)[2]` términos que se encuentran solamente en dos descripciones de vacantes y así consecutivamente. Así, podemos decir que entre más términos que solo aparecen esporádicamente en los textos, más alta será el índice de escazes de términos.

Por el momento, por tener demasiada escazes de términos, conservaremos todos y después los removeremos para comparar resultados. La siguiente gráfica muestra las palabras más frecuentes sin remover palabra alguna.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
require(ggplot2)
wf <- data.frame(word=names(freq), freq=freq) 

ggplot2::ggplot(subset(wf, freq > 40), aes(word, freq)) + 
    geom_bar(stat="identity") + 
    theme(axis.text.x=element_text(angle=45, hjust=1), 
          plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
    labs(title = "Palabras más Frecuentes en las Vacantes para Actuarios", 
         x = NULL, y = "Frecuencias")
```

Removiendo las palabras menos escazas veamos que palabras más frecuentes obtenemos.

```{r}
(dtms <- removeSparseTerms(dtm, 0.75))
```
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
require(ggplot2)
freq_sparse <- sort(colSums(as.matrix(dtms)), decreasing=TRUE)
wf_sparse <- data.frame(word=names(freq_sparse), freq=freq_sparse) 

ggplot2::ggplot(subset(wf_sparse, freq_sparse > 40), aes(word, freq)) + 
    geom_bar(stat="identity") + 
    theme(axis.text.x=element_text(angle=45, hjust=1), 
          plot.title = element_text(size = 15, face = "bold", hjust = 0.5)) +
    labs(title = "Palabras más Frecuentes en las Vacantes para Actuarios", 
         x = NULL, y = "Frecuencias")
```

Podemos observar que disminuyendo casi la mitad el índice de escazes se elimina más del 99% de nuestros términos. Por lo tanto, seguiremos utilizando nuestra matriz de términos con todas las palabras.

Por último, veamos que palabras están más relacionas con otras. Por ejemplo, buscaremos las palabras más asociadas con los términos 'titulado', 'gerente', 'seguros'. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
findAssocs(x = dtm, terms = "titulado", corlimit = 0.15)
findAssocs(x = dtm, terms = "gerente", corlimit = 0.3)
findAssocs(x = dtm, terms = "datos", corlimit = 0.3)
findAssocs(x = dtm, terms = "seguros", corlimit = 0.3)
```

Para el término 'titulado' no hay ninguna sorpresa, la mayoría de las palabras hacen alución a la situación final de la carrera ('pasante'), a los requisitos para trabajar ('indispensable'). 

El término 'gerente' me pareció más interesante, pues muestra términos relacionados con soft skills ('conciliar', 'coaching', 'acordar', 'obtener'). Lo cual podría sugerir un desarrollo más allá del técnico en alguien que pretenda un puesto de gerencia.

Si un actuario quisiera terminar en el ramo de seguros podría esperar muchos puestos de becarios, pues la correlación entre la palabra seguros y 'becario' es de 0.41%. Le seriviría investigar términos como 'corretaje' o 'reaseguro'.

Si quisieramos agrupar los términos más relacionados en todas las vacantes podríamos utilizar un análisis sencillo de conglomerados con un método Euclidiano. El siguiente código muestra la manera de hacerlo:

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.align="center"}
# Para este análisis si removemos los términos más escazos para utilizar un modelo
# sencillo de conglomerados utlizando una medida euclidiana
dtmss <- removeSparseTerms(dtm, 0.9)

d <- dist(t(dtmss), method="euclidian")   
fit <- hclust(d=d, method="ward.D")   

plot.new()
plot(fit, hang=-1, xlab = "", ylab = "", sub = "")

# Agrupamos con 4 clusters
groups <- cutree(fit, k=4)   
rect.hclust(fit, k=4, border="red")
```

Podemos notar que los grupos de palabras se relacionan respecto a las diferentes áreas en las que un actuario se puede desempeñar. 'Economía', 'finanzas' y 'administración' se muestran claramente en un grupo, mientras que 'ingenieria', 'sistemas' e 'industrial' se agrupan en otro conglomerado.

Aquí podemos interpretar el resultado de diferentes maneras. Regularmente, una vacante de actuaria no es específicamente para alguien egresado solamente de esa licenciatura. Por llas características en la formación de un actuario, podemos suponer que el profesionista puede desempeñar labores que abarcan desde la Economía, hasta alguna ingeniería.

# ¿Cuánto gana un actuario en México?

Finalmente, analicemos el salario promedio de un Actuario en México. Con los datos recabados podemos calcular el salario promedio ofrecido en las vacantes. Removiendo valores atípicos en nuestra muestra podemos representar los salarios ofrecidos en la siguiente gráfica:

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# filtering out jobs with no advertised salary or retaining those with annual salaries
actSalarios <- actuarios[!is.na(actuarios$minSal), ]

# plot annual salary cumulative distributions
actSalarios$avg_salario <- mapply(function(x,y){(x+y)/2}, actSalarios$minSal, actSalarios$maxSal)
actSalarios$type <- "actuario"


source(file = "https://goo.gl/UUyEzD")
outlierKD(actSalarios, avg_salario)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
load('~/Documents/RCode/actuaryJobsMx/dataset2.RData')

ggplot(actSalarios, aes(avg_salario)) + stat_ecdf() + 
    labs(title = "Salario Promedio del Actuario en México", 
         x = "Salario Mensual (MXN)", y = "Proporción Acumulada") + 
    theme(plot.subtitle = element_text(vjust = 1), 
          plot.caption = element_text(vjust = 1), 
          plot.title = element_text(size = 15, face = "bold", hjust = 0.5))
```

En la gráfica anterior podemos observar que a pesar de que la media de los salarios ofrecidos es de apenas $13,000 MXN al mes, un 50% de los trabajos ofrecen un sueldo promedio bastante alentador si tomamos en cuenta otras carreras.

Podemos observar más a detalle estos datos con la siguiente instrucción:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
summary(actSalarios$avg_salario)
```

# Conclusiones

El trabajo del actuario en México ha venido en aumento durante los últimos años en México, cada día más compañías se ven beneficiadas con las habilidades y conocimientos que un actuario puede ofrecer. Aunque al día de hoy, las compañias tradicionales (bancos, asegurados y financieras) son las responsables de contratar en su mayoria a los actuarios, podemos observar que poco a poco el actuario gana terreno en otras partes de la republica y cada día se diversifica más las responsabilidades de un actuario.

Una apuesta favorable es la de estudiar una licenciatura en Actuaria pues los sueldos promedios obtendios superan en buena medida los promedios nacionales de cualquier otra carrera. Aunque la demanda por nuevas herramientas y conocimientos hace de la Actuaría una carrera demandante, con una amplia variedad de temas a dominar, parece que siempre es bien recompezada.

